{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301fd597",
   "metadata": {},
   "source": [
    "# Portf√≥lio Processamento de Linguagem Natural - NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed814841",
   "metadata": {},
   "source": [
    "##### Cria√ß√£o do Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad638d",
   "metadata": {},
   "source": [
    "* Importa√ß√£o das biblotecas necess√°rias para o projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d563b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteca NLTK\n",
    "import nltk\n",
    "# Importando a classe Chat e o objeto reflections\n",
    "from nltk.chat.util import Chat, reflections\n",
    "# Importando o m√©todo sleep\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e935d3",
   "metadata": {},
   "source": [
    "* Realizando o download dos recursos para tokeniza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf9397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\leand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\leand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separar palavras e pontua√ß√µes em um texto\n",
    "nltk.download('punkt')\n",
    "# Remo√ß√£o de palavras comuns para precis√£o dos algoritmos de PNL\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349a0c4f",
   "metadata": {},
   "source": [
    "* Definindo reflections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876f5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflections = {\n",
    "    \"eu sou\": \"voc√™ √©\",\n",
    "    \"eu era\": \"voc√™ era\",\n",
    "    \"eu\": \"voc√™\",\n",
    "    \"meu\": \"seu\",\n",
    "    \"voc√™ √©\": \"eu sou\",\n",
    "    \"voc√™ era\": \"eu era\",\n",
    "    \"seu\": \"meu\",\n",
    "    \"sou\": \"√©\",\n",
    "    \"voc√™\": \"eu\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bff4c1",
   "metadata": {},
   "source": [
    "* Criando os padr√µes de di√°logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27347845",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversa = [\n",
    "    # Listas formatadas para reconhecem qualquer combina√ß√£o de letras acentuadas, mai√∫sculas ou min√∫sculas.\n",
    "    [r\"(?i)\\b[o√≥√≤√¥√µ√∂]l[a√°√†√¢√£√§]\\b\", [\"Ol√°! Como vai?\"]],\n",
    "    [r\"(?i).*bem\", [\"Que bom!üòé\"]],\n",
    "    [r\"(?i)\\boi\\b\", [\"Como vai?\"]],\n",
    "    [r\"(?i)\\b(ok|certo|positivo|entendido|compreendido|beleza|√≥timo|otimo|n√£o h√° de que|por nada|n√£o por isso)\\b\", [\"ü§ù\"]],\n",
    "    [r\"\\b(tudo bem|TUDO BEM|tudo bem!|TUDO BEM!)\\b\", [\"Isso √© bom!üëç\"]],\n",
    "    [r\"(como vai?|como voc√™ est√°?|como voce esta?|E voc√™?|E voce?|bem e voc√™?|bem e voce?)\",\n",
    "     [\"Estou bem, Grato por perguntar!‚ù§Ô∏è\"]],\n",
    "    [r\"(?i)me ajuda?\", [\"Claro, em que posso ser √∫til?\"]],\n",
    "    [\"(?i)preciso de ajuda\", [\"Claro, em que posso ser √∫til?\"]],\n",
    "    [\"(?i)pode ajudar?\", [\"Claro, em que posso ser √∫til?\"]],\n",
    "    [r\"(?i).*pode me ajudar?\", [\"Claro, em que posso ser √∫til?\"]],\n",
    "    [r\"(?i)\\bajuda[r]?\\b\", [\"Claro, em que posso ser √∫til?\"]],\n",
    "    [r\"(?i).*brincando\", [\"Sem problemas, voc√™ tem bom humor üòÇ\"]],\n",
    "    [r\"(?i).*um chatbot\", [\"Que legal, sugiro o estudo da biblioteca NLTK\"]],\n",
    "    [r\"(?i).*indica um site?\", [\"Claro, o site oficial √©: https://www.nltk.org/\"]],\n",
    "    [r\"(?i).*indicar um site?\", [\"Claro, o site oficial √©: https://www.nltk.org/\"]],\n",
    "    [r\"(agrade√ßo|grato|obrigado|muito grato|muito obrigado)\",\n",
    "     [\"N√£o h√° de que! Voc√™ encontrar√° muitos t√≥picos √∫teis no site oficial da biblioteca.\"]],\n",
    "    [r\"(?i).*finalizar.*\", [\"OK, conte comigo sempre que precisar. At√© mais!\"]],\n",
    "    [r\"(?i)\\bquem .*criou.* voc√™\\b\", [\"Foi um estudante de ci√™ncia de dados, O nome dele √© Leandro.\"]],\n",
    "    [r\"(?i)\\b(legal|que legal|bacana|que bacana|massa|que massa|irado|que irado|gostei|tai gostei|foda|que foda|top|que top|show|que show)\\b\", \n",
    "     [\"Interessante, n√£o √© mesmo?! √â o poder da biblioteca NLTK.üòÅ\"]],\n",
    "    # Qualquer palavra/frase fora da lista, retona que o chat ainda n√£o est√° preparado para a solicita√ß√£o\n",
    "    [\".*\", [\"Ainda n√£o sou capaz de reconhecer a frase/texto ou n√£o possuo conhecimento nesse assunto.\"]]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebcef92",
   "metadata": {},
   "source": [
    "* Criando o chat com padr√µes de pergunta e resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eec9e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = Chat(conversa, reflections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a087d215",
   "metadata": {},
   "source": [
    "* Criando o loop do chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bbcd75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por gentileza, para come√ßar digite o seu nome: \n",
      "\n",
      "Leandro\n",
      "\n",
      "Rob√¥: Ol√°, Leandro! Meu nome √© Jullees, e sou um chat virtual.\n",
      "Vamos come√ßar.\n",
      "Digite aqui: Ol√° Jullees\n",
      "Rob√¥:  Ol√°! Como vai?\n",
      "\n",
      "Digite aqui: estou bem\n",
      "Rob√¥:  Que bom!üòé\n",
      "\n",
      "Digite aqui: e voc√™, como vai?\n",
      "Rob√¥:  Estou bem, Grato por perguntar!‚ù§Ô∏è\n",
      "\n",
      "Digite aqui: por nada\n",
      "Rob√¥:  ü§ù\n",
      "\n",
      "Digite aqui: pode me ajudar?\n",
      "Rob√¥:  Claro, em que posso ser √∫til?\n",
      "\n",
      "Digite aqui: Quero ficar rico e ficar numa boa\n",
      "Rob√¥:  Ainda n√£o sou capaz de reconhecer a frase/texto ou n√£o possuo conhecimento nesse assunto.\n",
      "\n",
      "Digite aqui: Estou brincando\n",
      "Rob√¥:  Sem problemas, voc√™ tem bom humor üòÇ\n",
      "\n",
      "Digite aqui: agora √© serio, estou desenvolvendo um chatbot\n",
      "Rob√¥:  Que legal, sugiro o estudo da biblioteca NLTK\n",
      "\n",
      "Digite aqui: indica um site?\n",
      "Rob√¥:  Claro, o site oficial √©: https://www.nltk.org/\n",
      "\n",
      "Digite aqui: grato\n",
      "Rob√¥:  N√£o h√° de que! Voc√™ encontrar√° muitos t√≥picos √∫teis no site oficial da biblioteca.\n",
      "\n",
      "Digite aqui: quem criou voc√™?\n",
      "Rob√¥:  Foi um estudante de ci√™ncia de dados, O nome dele √© Leandro.\n",
      "\n",
      "Digite aqui: que legal!\n",
      "Rob√¥:  Interessante, n√£o √© mesmo?! √â o poder da biblioteca NLTK.üòÅ\n",
      "\n",
      "Digite aqui: agora, vou finalizar a nossa conversa\n",
      "Rob√¥:  OK, conte comigo sempre que precisar. At√© mais!\n",
      "\n",
      "Digite aqui: entendido\n",
      "Rob√¥:  ü§ù\n",
      "\n",
      "Digite aqui: Sair\n",
      "\n",
      "Chat finalizado. At√© mais Leandro\n"
     ]
    }
   ],
   "source": [
    "# Definindo um input para o bot tratar o usu√°rio pelo nome inserido\n",
    "nome = input(\"Por gentileza, para come√ßar digite o seu nome: \\n\\n\")\n",
    "# Loop para funcionamento do chat com bloco try/except\n",
    "def dialogo(nome):\n",
    "    try:\n",
    "        print(f\"\\nRob√¥: Ol√°, {nome}! Meu nome √© Jullees, e sou um chat virtual.\\nVamos come√ßar.\")\n",
    "        sleep(2)\n",
    "        while True:\n",
    "            pessoa = input(\"Digite aqui: \")\n",
    "            sleep(1)\n",
    "            # Criando uma condi√ß√£o para reconhecer a sa√≠da do chat\n",
    "            if pessoa == \"sair\" or pessoa == \"SAIR\" or pessoa == 'Sair':\n",
    "                print(\"\\nChat finalizado. At√© mais\", nome)\n",
    "                break\n",
    "            else:\n",
    "                chat = bot.respond(pessoa)\n",
    "                sleep(1)\n",
    "                print(\"Rob√¥: \", chat, end=\"\\n\\n\")\n",
    "                sleep(1)\n",
    "    # Tratativa e demonstra√ß√£o do erro, caso houver algum            \n",
    "    except Exception as e:\n",
    "        print(\"Ocorreu um erro: \", '\\n', e)\n",
    "# Chamando a fun√ß√£o dialogo\n",
    "dialogo(nome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637a8a2",
   "metadata": {},
   "source": [
    "#### Criando o Processo de Tokeniza√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec62ff",
   "metadata": {},
   "source": [
    "* Importando as bibliotecas para tokeniza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47670233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59734a5",
   "metadata": {},
   "source": [
    "* Definido stopword em pt-br e criando a vari√°vel que cont√©m o texto para tokeniza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4da17a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o recurso stopwords para a lingua portuguesa\n",
    "pt_br = stopwords.words('portuguese')\n",
    "# Texto para tokeniza√ß√£o\n",
    "texto = '''Neste texto, ser√° realizado o teste da funcionalidade\n",
    "           do recurso para tokeniza√ß√£o. Ap√≥s os processos, ser√° \n",
    "           poss√≠vel identificar a efic√°cia da biblioteca NLTK e\n",
    "           seus recursos.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f4548",
   "metadata": {},
   "source": [
    "* Criando o processo de tokeniza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb669951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto tokenizado: \n",
      "\n",
      " ['Neste', 'texto', ',', 'ser√°', 'realizado', 'o', 'teste', 'da', 'funcionalidade', 'do', 'recurso', 'para', 'tokeniza√ß√£o', '.', 'Ap√≥s', 'os', 'processos', ',', 'ser√°', 'poss√≠vel', 'identificar', 'a', 'efic√°cia', 'da', 'biblioteca', 'NLTK', 'e', 'seus', 'recursos', '.']\n"
     ]
    }
   ],
   "source": [
    "palavras = word_tokenize(texto, language='portuguese')\n",
    "print(\"Texto tokenizado:\", \"\\n\\n\", palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d67d61a",
   "metadata": {},
   "source": [
    "* Criando uma nova lista chamada sem_stopwords que cont√©m todas as palavras \n",
    "  da lista palavras que n√£o est√£o na lista de stopwords removendo as palavras \n",
    "  comuns que geralmente n√£o contribuem para o significado de uma frase da lista de palavras reduzindo o ru√≠do dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4fac2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neste', 'texto', ',', 'realizado', 'teste', 'funcionalidade', 'recurso', 'tokeniza√ß√£o', '.', 'Ap√≥s', 'processos', ',', 'poss√≠vel', 'identificar', 'efic√°cia', 'biblioteca', 'NLTK', 'recursos', '.']\n"
     ]
    }
   ],
   "source": [
    "sem_stopwords = [palavra for palavra in palavras if palavra.lower() not in pt_br]\n",
    "print(sem_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4310a74",
   "metadata": {},
   "source": [
    "#### Criando o processo de an√°lise de sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed5f787",
   "metadata": {},
   "source": [
    "* Importando as biblotecas necess√°rias para o projeto de an√°lise de sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e74f37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando TextBlob e NaiveBayesClassifier\n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f8738",
   "metadata": {},
   "source": [
    "* Criando a fun√ß√£o para analisar os sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd1ed810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite algo para an√°lise de sentimento: Fiquei insatisfeito com o produto adquirido\n",
      "\n",
      "A frase digitada foi: Fiquei insatisfeito com o produto adquirido\n",
      "\n",
      "An√°lise de Sentimento:  üëéüò¢üëéIsso me parece Negativoüëéüò¢üëé\n"
     ]
    }
   ],
   "source": [
    "def analise(texto):\n",
    "    # Exemplo de conjunto de treinamento\n",
    "    treino = [\n",
    "        ('Eu amo esse produto!', 'pos'), ('Estou muito feliz.', 'pos'), ('Isso √© muito bom', 'pos'), ('Eu estou bem', 'pos'),\n",
    "        ('Esse rapaz √© legal', 'pos'), (' Esse creme √© otimo', 'pos'), ('Estou descansado', 'pos'), ('Estou apaixonado', 'pos'),\n",
    "        ('Gostei muito do show', 'pos'), ('Estou me sentindo mal', 'neg'), ('Estou me sentindo mau', 'neg'), \n",
    "        ('Estou muito cansado', 'neg'), ('Tenho medo de morrer', 'neg'), ('Estou doente', 'neg'),('N√£o gostei do sabor', 'neg'),\n",
    "        ('Estou me sentindo infeliz', 'neg'), ('Esse processo n√£o funciona', 'neg'), ('Isso √© terr√≠vel.', 'neg'), \n",
    "        ('Isso √© pessimo', 'neg'), ('Estou com muita raiva.', 'neg'), ('Estou com muita odio.', 'neg')\n",
    "    ]\n",
    "    \n",
    "    # Treinamento do classificador\n",
    "    cl = NaiveBayesClassifier(treino)\n",
    "    # Definindo a classifica√ß√£o do texto para a vari√°vel 'entrada'\n",
    "    entrada = TextBlob(texto, classifier=cl)\n",
    "    #Criando \n",
    "    for i in entrada.sentences:\n",
    "        print('\\nA frase digitada foi:', i, end='\\n')\n",
    "        sleep(2)\n",
    "        if i.classify() == 'neg':\n",
    "            return 'üëéüò¢üëéIsso me parece Negativoüëéüò¢üëé'\n",
    "        elif i.classify() == 'pos':\n",
    "            return 'üëçüòÅüëçIsso me parece Positivo!üëçüòÅüëç'\n",
    "        else:\n",
    "            return 'ü§îü§îü§îN√£o consigo determinar o sentimento com exatid√£o.ü§îü§îü§î'\n",
    "\n",
    "# Utilizando a fun√ß√£o 'analise'\n",
    "entrada = input(\"Digite algo para an√°lise de sentimento: \")\n",
    "sentimento = analise(entrada)\n",
    "print(\"\\nAn√°lise de Sentimento: \", sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64954985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
